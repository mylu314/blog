## <span id="jump0">目录<span>
  
  * [径向基函数 radial basis function RBF](#jump1)
  * [ORACLE](#jump2)
  * [metric/distance function](#jump3)
  * [Radial basis function network](#jump4)
  * [machine learning idea](#jump5)

## <span id="jump1">径向基函数 radial basis function RBF<span>

  ### [radial basis function](https://en.wikipedia.org/wiki/Radial_basis_function)
  
  * radical
    * 取值仅依赖于对象距离中心点的距离
    * 可以用来描述相似度
  * basis
    * kernels linearly independent
    * kernels interpolation matrix non-singular
 
  
[返回目录](#jump0)


## <span id="jump2">ORACLE<span>
  
  ### [REM](https://stackoverflow.com/questions/8932354/what-does-exactly-do-the-command-rem-inserting-into-table-name-in-oracle)
  
  * remark
  * 注释
 
  ### [SET DEFINE OFF](https://stackoverflow.com/questions/34332639/when-or-why-to-use-a-set-define-off-in-oracle-database)
  
  * SQL Plus 关闭 & 符号的替代功能
  * 默认 ON
  * navicat 报错 invalid SQL statement
  
 
[返回目录](#jump0)

## <span id="jump3">metric/distance function<span>
  
  ### [metric](https://en.wikipedia.org/wiki/Metric_(mathematics))
 
  * Euclidean distance
  * discrete metric
  * Graph metric
    * shortest directed or undirected path
  * [edit distance](https://en.wikipedia.org/wiki/Edit_distance) similarity between two strings/words
    * Levenshtein distance
      * a string metric for measuring the difference between two sequences
      * 度量从 string a 到 string b 需要变换多少步
      * allows deletion, insertion and substitution
    * Longest common subsequence
      * allows only insertion and deletion, not substitution
    * Hamming distance
      * allows only substitution
    * Damerau–Levenshtein distance
      * allows insertion, deletion, substitution, and the transposition of two adjacent characters
    * Jaro distance
      * allows only transposition
  * [Graph edit distance](https://en.wikipedia.org/wiki/Graph_edit_distance) similarity between two graphs
    * related to edit distance by treating strings as graph(character as node, position as directed relations)
  * [Wasserstein metric]() similarity between two probability distributions(look like piles of earth)
    * amount of earth
    * mean distance to move 

[返回目录](#jump0)

## <span id="jump4">Radial basis function network<span>
  
  ### [Radial basis function network wiki](https://en.wikipedia.org/wiki/Radial_basis_function_network)
  
<p align="center">
  <img src=https://github.com/mylu314/blog/blob/main/images/Radial_funktion_network.png>
<p>
 
  ### item4.2

[返回目录](#jump0)


## <span id="jump5">machine learning idea<span>
  
  * Beginning: given a new sample with features vector *x*, predict the value(y) of the new sample.
    * what u have is the train dataset.
    * ur idea is to guess(sum by weight) the value of the new sample with the values of similar ones in the train dataset.
      * similarity
      * weight
    * note: u probably haven't thought about the relationships ![](http://latex.codecogs.com/gif.latex?y=f\left(x\right)) between features and value of each sample point,u only have the idea of ![](http://latex.codecogs.com/gif.latex?\hat{y}=\sum_{i}^{}w_{i}y_{i}).
  * Then: Now pick a method of measuring the similarity. Bsed on the similarity results, u can decide the weights since generally u give more weight to the ones more similar to the new sample.
  * Problem: Well, u need to obey a rule that all weights sum to one. Perhaps it seems straight-forward to find a fixed and specific way of computing weights. Like ![](http://latex.codecogs.com/gif.latex?weight=\frac{1/distance}{\sum{\left(1/distance\right)}}). Speaking of a fixed way of determing weights, maybe u realize it's actually a sets of rules, or from another perspective, a model. But which model is the best?
  * Then: This fixed model suits everyone including all members in the train dataset. Then comes the loss. The loss of the train dataset. Regarding the sample in the train dataset, u still want to get a good guess through ur model assuming u don't know its value. 
    * note: u probably haven't thought about the relationships ![](http://latex.codecogs.com/gif.latex?y=f\left(x\right)) between features and value of each sample point.
  * Question: Now the quesiton is how to get a good model. It's not straight-forward since u don't know what a good model means from another perspective. So probably u try to jump out and look at the problem as a whole. U realize the instinct of this problem is to guess sample's value based on the information of its features, that is study the relationship between *x* and *y*. And the key point here is that u find out a good model means a better understanding of the relationship between *x* and *y*.
  * Final: So now u build a model describing best the relationship between *x* and *y* to find the best rules of weights design.

  
[返回目录](#jump0)
